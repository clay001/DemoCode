{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5486e-18, 4.5559e-41, 3.5486e-18],\n",
       "        [4.5559e-41, 6.9169e-01, 1.7900e+00],\n",
       "        [1.3685e+00, 1.0897e-01, 7.0541e-01],\n",
       "        [1.1366e+00, 7.4956e-01, 1.6054e+00],\n",
       "        [1.1774e+00, 1.0025e+00, 7.4706e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import torch\n",
    "x = torch.Tensor(5,3)\n",
    "x1 = torch.rand(5,3)    #创建不同形状的随机矩阵\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5485, 0.7410, 0.3882],\n",
       "        [0.5657, 0.7194, 0.6859],\n",
       "        [0.0033, 0.6657, 0.6802],\n",
       "        [0.6450, 0.2225, 0.6908],\n",
       "        [0.1307, 0.8957, 0.3540]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5,3)\n",
    "z = x + y\n",
    "#torch.add(x,y)\n",
    "z.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5486e-18, 4.5559e-41, 3.5486e-18],\n",
       "        [4.5559e-41, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特别注明：任何可以改变tensor内容的操作都会在方法名后加一个下划线'_'\n",
    "result = torch.Tensor(5,3)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5243, 1.2738, 0.5558],\n",
       "        [1.4285, 0.6917, 1.7900],\n",
       "        [1.3685, 0.1090, 0.7054],\n",
       "        [1.1366, 0.7496, 1.6054],\n",
       "        [1.1774, 1.0025, 0.7471]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6242, 0.8084, 0.4474],\n",
       "        [0.6672, 0.6859, 0.8313],\n",
       "        [0.9246, 0.0205, 0.6707],\n",
       "        [0.9077, 0.3558, 0.7973],\n",
       "        [0.6770, 0.7630, 0.2384]], device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6242, 0.8084, 0.4474],\n",
       "        [0.6672, 0.6859, 0.8313],\n",
       "        [0.9246, 0.0205, 0.6707],\n",
       "        [0.9077, 0.3558, 0.7973],\n",
       "        [0.6770, 0.7630, 0.2384]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5)\n",
    "b = a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a,1,out = a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    z = x + y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2483, 1.6168, 0.8949],\n",
       "        [1.3344, 1.3718, 1.6626],\n",
       "        [1.8491, 0.0411, 1.3413],\n",
       "        [1.8155, 0.7117, 1.5946],\n",
       "        [1.3540, 1.5261, 0.4769]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable \n",
    "x = Variable(torch.ones(2,2),requires_grad = True)\n",
    "y = x + 2\n",
    "#y.creator\n",
    "z = y*y*3\n",
    "out = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000, 4.5000],\n",
       "        [4.5000, 4.5000]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([-2.1684, -0.0643 , 0.8492])\n",
    "x = Variable(x, requires_grad = True)\n",
    "y = x * 2\n",
    "while y.norm() < 1000:\n",
    "    y = y * 2\n",
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "#y.backward(torch.Tensor(3,1))\n",
    "y.backward(gradients)\n",
    "x.grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e-01, 1.0000e+00, 1.0000e-04])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = x.view(-1,self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "net \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0114,  0.1414, -0.0406,  0.0852, -0.0664, -0.0638, -0.0630,  0.0084,\n",
      "          0.0254,  0.0764]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = Variable(torch.randn(1,1,32,32))\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-7f4895a85a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'conv1' is not defined"
     ]
    }
   ],
   "source": [
    "target = Variable(torch.range(1,10))\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###新笔记\n",
    "import torch\n",
    "x = torch.ones(2,2,requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7f65480bdeb8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x+2\n",
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.mean(y*y)\n",
    "z.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5000, 1.5000],\n",
      "        [1.5000, 1.5000]])\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-59585ff5f284>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#记录每一个batch的损失\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#128个样本点被分为一个batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVarialble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#http://capitalbikeshare.com/system-data 共享单车的数据\n",
    "#www.freemeteo.com 对数据可以进行独热编码\n",
    "#因为有些属性不是数值类型或者大小含义不等，要先预处理\n",
    "#类型数据（星期几）独热编码，N个类型，一种一个置为1，其他0\n",
    "#数值变量，假设正态分布进行标准化\n",
    "#时间横移的数据就变成一个圆柱体\n",
    "\n",
    "input_size = 59    #处理后的特征属性,输入单元\n",
    "hidden_size = 10 \n",
    "output_size = 1\n",
    "batch_size = 128   #分批\n",
    "neu = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_size,hidden_size),\n",
    "    torch.nn.Sigmoid(),\n",
    "    torch.nn.Linear(hidden_size,output_size),\n",
    ")\n",
    "cost = torch.nn.MSELoss()        #等价于torch.mean((y-y*)^2) 预测问题一般用的\n",
    "                                    #均方差误差\n",
    "optimizer = torch.optim.SGD(net.parameters(),lr=0.01)\n",
    "\n",
    "for i in range(2000):\n",
    "    batch_loss = [] #记录每一个batch的损失\n",
    "    #128个样本点被分为一个batch\n",
    "    for start in range(0,len(X),batch_size):\n",
    "        end = start + batch_size if start + batch_size < len(X) else len(X)\n",
    "        xx = Varialble(torch.FloatTensor(X[start:end]))\n",
    "        yy = Variable(torch.FloatTensor(Y[start:end]))\n",
    "        predict = neu(xx)         #模型预测\n",
    "        loss = cost(predict,yy)\n",
    "        optimizer.zero_grad()    #优化器存储梯度置0\n",
    "        loss.backward()\n",
    "        optimizer.step()   #优化器开始运行一步，更新所有的参数\n",
    "        batch_loss.append(loss.data.numpy())  #加上这一步的loss值\n",
    "    if i%100 ==0:\n",
    "        losses.append(np.mean(batch_loss))\n",
    "        print(i,np.mean(batch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文本分类问题\n",
    "#词袋模型，对语料库中的所有单词排序，语料有多少词，向量就有多少维度，对于一个句子\n",
    "#统计出每一个单词的出现次数，并将这个数字填充到相应位置，出现次数除以这句话中的总\n",
    "#次数\n",
    "model = nn.Sequencial(\n",
    "    nn.Linear(7139,10),   #7139个单词\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10,2),\n",
    "    nn.LogSoftmax(dim = 1),\n",
    ") \n",
    "\n",
    "cost = torch.nn.NLLLoss()   #分类问题一般用的交叉熵损失\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "records = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i,data in enumerate(zip(train_data,train_label)):\n",
    "        #enumerate(sequence, [start=0]) 组合成一个索引序列\n",
    "        #zip把可迭代对象打包成一个元组，zip（*x）是反向的过程\n",
    "        x,y = data\n",
    "        x = Variable(torch.FloatTensor(x).view(1,-1)) \n",
    "        #view函数是将多行的tensor拼成一行\n",
    "        y = Variable(torch.LongTensor(np.array([y])))  #这儿也不是很懂为什么要【y】\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        predict = model(x)\n",
    "        loss = cost(predict,y)\n",
    "        losses.append(loss.data.numpy()[0])    #这里不是很懂为什么要加上【0】\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "if i%3000 ==0:\n",
    "    val_losses = []\n",
    "    rights = [] #在校验集上进行试验\n",
    "    for j,val in enumerate(zip(valid_data,valid_label)):\n",
    "        x,y = val\n",
    "        x = Variable(torch.FloatTensor(x).view(1,-1))\n",
    "        y = Variable(torch.LongTensor(np.array([y])))\n",
    "        predict = model(x)\n",
    "        #调用rightness函数来计算准确率\n",
    "        right = rightness(predict,y)\n",
    "        rights.append(right)\n",
    "        loss = cost(predict,y)\n",
    "        val_losses.append(loss.data.numpy()[0])\n",
    "        #计算平均准确度\n",
    "        right_ratio = 1.0*np.sum([i[0] for i in rights])/np.sum([i[1] for i in rights])   \n",
    "        #这里不是很懂为什么sum（）里要加上【】\n",
    "        print(\"第{}轮，训练损失：{:.2f},校验损失：{:.2f},校验准确率：{:.2f}\".format\n",
    "             (epoch,np.mean(losses),np.mean(val_losses),right_ratio))\n",
    "        #Python2.6 开始，新增了一种格式化字符串的函数 str.format()，\n",
    "        #它增强了字符串格式化的功能。基本语法是通过 {} 和 : 来代替以前的 % 。\n",
    "        \n",
    "        records.append([np.mean(losses),np.mean(val_losses),right_ratio])\n",
    "        \n",
    "#文本分类-词袋模型-神经网络分类器的实现-训练集校验集和测试集    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#卷积神经网络\n",
    "#卷积核，越白表示权重越大，是看原始图像和卷积核的相似程度。\n",
    "#在表示的时候可以把最后得到的很多个特征图拼在一起组成一个立方体\n",
    "#池化操作是在每一个窗口中取一根最大值得到一个新图像，作用是模糊化获取更粗线条的信息\n",
    "#然后再卷积，再池化\n",
    "#最后特征图拉平成一个一维向量，然后全连接一个前馈网络，最后连一个logsoftmax层，得到\n",
    "#每一个类别的概率对数值\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_dataset = dsets.MNIST(root='./data',#文件存放路径\n",
    "                            train = True,\n",
    "                            transform = transforms.ToTensor(),\n",
    "                            download = True)\n",
    "test_dataset = dsets.MNIST(root = './data',\n",
    "                            train = False,\n",
    "                            transform = transforms.ToTensor())\n",
    "#数据集的加载\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                          shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分离校验集，采样器\n",
    "indices = range(len(test_dataset))\n",
    "indices_val = indices[:5000]        #校验数据集\n",
    "indices_test = indices[5000:]\n",
    "\n",
    "#构造采样器\n",
    "sampler_val = torch.utils.data.sampler.SubsetRandomSampler(indices_val)\n",
    "sampler_test = torch.utils.data.sampler.SubsetRandomSampler(indices_test)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                               batch_size = batch_size,\n",
    "                                               #shuffle = True,\n",
    "                                               sampler = sampler_val)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         #shuffle = True,\n",
    "                                         sampler = sampler_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class ConvNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,4,5,padding = 2)\n",
    "        #黑白，输入通道为1，输出通道（卷积核的个数），5是窗口的大小\n",
    "        self.pool = nn.Maxpool2d(2,2)\n",
    "        #2是池化的窗口大小\n",
    "        self.conv2 = conv2d(4,8,5,padding = 2)\n",
    "        self.fc1 = nn.Linear(image_size//4 * image_size //4 *8,512) \n",
    "        # 是地板除的意思,两个2池化被8个输出通道拉平，传给512\n",
    "        self.fc2 = nn.Linear(512,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, image_size // 4* image_size//4 * 8)\n",
    "        #不知道和（-1,1）有什么区别\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x,training = self.training)  \n",
    "        #这个函数不太懂,dropout是在训练过程中随机的删除一些连边的情况来增加鲁棒性，\n",
    "        #drop率可为0.5，且只在训练时候使用，在测试的时候不使用\n",
    "        #是防止过拟合的技术\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #模型在训练集上训练\n",
    "        net.train()   #打开training变量\n",
    "        output = net(data)\n",
    "        \n",
    "        loss = criterion(output,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx %100 == 0:\n",
    "            #打印和记录数据\n",
    "            net.eval()\n",
    "            val_rights = []\n",
    "            for (data,target) in validation_loader:\n",
    "                data,target = Variable(data),Variable(target)\n",
    "               \n",
    "                output = net(data)\n",
    "                \n",
    "                right = rightness(output,target)\n",
    "                \n",
    "            \n",
    "            \n",
    "net.eval()  \n",
    "#关闭training 变量，打开的时候dropout才能发挥作用\n",
    "\n",
    "#在测试集上运行\n",
    "test.loss = 0 \n",
    "correct = 0\n",
    "for data,target in test_loader:\n",
    "    data, target  = Variable(data), Variable(target)\n",
    "    \n",
    "    output = net(data)\n",
    "    \n",
    "    val = rightness(output, target)\n",
    "    \n",
    "#训练曲线要在校验曲线的上方（这个说法应该是不准确的，应该说是走势上不能有相反的动向）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#迁移学习允许训练集和测试集有不同的分布\n",
    "#预训练模式，是迁移值作为初始值\n",
    "#固定值模式，一直固定\n",
    "#Hymenoptera genome database 224*224像素 彩色\n",
    "#全部的数据只有224条样本\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import copy\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "image_size = 224\n",
    "#从data_dir/train中加载文件\n",
    "#1.随机从原始图像中切下来一块224*224区域\n",
    "#2.随机水平翻转\n",
    "#3.将图像的色彩数值标准化\n",
    "train_dataset = datasets.ImageFolder(os.path.join(data_dir,\"train\"),\n",
    "                                    transforms.Compose([\n",
    "                                        transforms.RandomSizedCrop(image_size),\n",
    "                                        transforms.RandomHorizaontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                            [0.229,0.224,0.225])\n",
    "                                        \n",
    "                                    ])\n",
    "                                    )\n",
    "\n",
    "#扩大到256，中心对称裁剪，转成张量，颜色标准化处理\n",
    "val_dataset = datasets.ImageFolder(os.path.join(data_dir,\"val\"),\n",
    "                                   transforms.Compose([\n",
    "                                       transforms.Scale(256),\n",
    "                                       transforms.CenterCrop(image_size),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize([0.485,0.456,0.406],\n",
    "                                                            [0.229,0.224,0.225])\n",
    "                                   ])\n",
    "                                  )\n",
    "#创建相应的数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=4,shuffle = True,\n",
    "                                           num_workers = 4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,batch_size = 4,shuffle=True,\n",
    "                                         num_worker = 4)\n",
    "\n",
    "num_classes = len(train_datasets.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'resnet18'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-501baed99bb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#这一步可选,加上就变成了固定形\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 535\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'resnet18'"
     ]
    }
   ],
   "source": [
    "net = model.resnet18(pretrained = True)\n",
    "#这一步可选,加上就变成了固定形\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "#存储了最后两层神经元的输入神经元个数\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ftrs,2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.0001,momentum=0.9)  #动量法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练过程\n",
    "record = []\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    train_rights = []\n",
    "    train_losses = []\n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        data,target = Variable(data),Variable(target)\n",
    "        #完成一次预测\n",
    "        output = net(data)\n",
    "        loss = criterion(output,target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = rightness(output,target)\n",
    "        \n",
    "        train_rights.append(right)\n",
    "        train_losses.append(loss.data.numpy())\n",
    "        \n",
    "#这个上面的校验数据loss又是基本在训练数据的上方了\n",
    "#迁移学习有望解决数据稀缺的问题，是神经网络的切分和组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像风格迁移，生成一个随机噪声，然后在内容在相似一张图片，风格上相似另一张图片\n",
    "#相似只是把两张图片输入到同一个CNN中，让其进行图层卷积，高层卷积出来的特征图是不是相同\n",
    "\n",
    "#Lc(figure_1,figure_2)这个是高层特征图相似度，反映了内容上的相似程度\n",
    "#低层特征图，再其基础上再计算一下gram矩阵（拉成一列然后自乘），就可以反应风格上的相似程度\n",
    "#底层特征图需要把很多层加起来取平均\n",
    "\n",
    "#最后得到一个L = αLc + βLs\n",
    "\n",
    "\n",
    "#CNN的选取，选了VGG19（牛津视觉几何组，特点是卷积核小3*3，且网络很深），直接固定住就可以\n",
    "#读入图片 === 读入VGG === 构造新的计算图 === 开始迭代优化\n",
    "\n",
    "#添加了输入图像模块和风格损失和内容损失\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import copy \n",
    "\n",
    "#是否用GPU进行计算\n",
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#风格图像的路径，自行设定\n",
    "style = 'images/escher.jpg'\n",
    "#内容图像的路径\n",
    "content = 'images/portrait1.jpg'\n",
    "\n",
    "#图像大小相同\n",
    "\n",
    "#定义两个权重\n",
    "style_weight = 1000\n",
    "content_weight = 1\n",
    "\n",
    "#图像预处理\n",
    "#缩放到相同的大小\n",
    "#转化为Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.torch/models/vgg19-dcbb9e9d.pth\n",
      "574673361it [01:28, 6514303.70it/s] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-180a3cf33740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Anacondas/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Anacondas/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \"\"\"\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "cnn = models.vgg19(pretrained = True).features\n",
    "if use_cuda:\n",
    "    cnn = cnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retain_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8b9cc0a435b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#内容损失模块(由于也是新的节点，所以也定义成神经网络结构)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mContentLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mContentLoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#目标图像的特征图和原始计算图分离\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-8b9cc0a435b8>\u001b[0m in \u001b[0;36mContentLoss\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m#开始反向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#不是很理解\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'retain_graph' is not defined"
     ]
    }
   ],
   "source": [
    "#内容损失模块(由于也是新的节点，所以也定义成神经网络结构)\n",
    "class ContentLoss(nn.Module):\n",
    "    def __init__(self,target,weight):  #target是目标图片经CNN提取的特征图\n",
    "        super(ContentLoss,self).__init__()\n",
    "        #目标图像的特征图和原始计算图分离\n",
    "        self.target = target.detach()*weight\n",
    "        self.weight = weight\n",
    "        self.criterion = nn.MSELoss()\n",
    "    def forward(self,input):    #input是原始噪声图片经CNN提取的特征图\n",
    "        #输入的input是一个特征图\n",
    "        #计算均方误差\n",
    "        self.loss = self.criterion(input*self.weight, self.target)\n",
    "        self.output = input\n",
    "        return self.output\n",
    "    def backward(retain_graph = retain_graph):\n",
    "        #开始反向传播\n",
    "        self.loss.backward(retain_graph = retain_graph)  #不是很理解\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleLoss(nn.Module):\n",
    "    def __init__(self,target,weight):\n",
    "        super(StyleLoss,self).__init__()\n",
    "        self.target = target.detach()*weight\n",
    "        self.weight = weight\n",
    "        self.criterion = nn.MSELoss()\n",
    "    def forward(self,input):\n",
    "        self.output = input.clone()\n",
    "        input = input.cida() if use_cuda else input\n",
    "        self_G = Gram(input)\n",
    "        self_G.mul_(self.weight)\n",
    "        #计算损失函数，即输入特征图的gram矩阵和目标特征图的gram矩阵之间的差异\n",
    "        self.loss = self.criterion(self_G,self.target)\n",
    "        return self.output\n",
    "    def backward(self,retain_graph = True):\n",
    "        #反向传播算法\n",
    "        self.loss.backward(retain_graph = retain_graph)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_losses = []\n",
    "style_losses = []\n",
    "model = nn.Sequential()\n",
    "#一个新的序贯网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 1\n",
    "for layer in list(cnn):\n",
    "    if isinstance(layer,nn.Conv2d):\n",
    "        name = \"conv_\" + str(i)  #将已经加载的模块放到新的神经模块中去\n",
    "        model.add_module(name,layer)\n",
    "        \n",
    "        if name in content_layers:\n",
    "            #如果当前模型在定义好的要计算内容损失的层\n",
    "            target = model(content_img).clone()\n",
    "            #将内容图像当前层的feature信息拷贝到target中\n",
    "            content_loss = ContentLoss(target, content_weight)\n",
    "            #定义content_loss的目标函数\n",
    "            content_loss = content_loss.cuda() if use_cuda else content_loss\n",
    "            module.add(\"content_loss\" +str(i),content_loss)\n",
    "            #加上这么一层\n",
    "            content_losses.append(content_loss)\n",
    "            \n",
    "        if name in style_layers:\n",
    "            #如果当前层在指定的风格层中\n",
    "            target_feature = model(style_img).clone()\n",
    "            target_feature = target_feature.cuda() if use_cuda else target_feature\n",
    "            traget_feature_gram = Gram(target_feature)\n",
    "            style_loss = StyleLoss(target_feature_gram,style_weight)\n",
    "            style_loss = style_loss.cuda() if use_cuda else style_loss\n",
    "            model.add_module(\"style_loss_\" +str(i),style_loss)\n",
    "            style_losses.append(style_loss)\n",
    "    \n",
    "    #省略了其他的非卷积层一样的也是简单copy就可以    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-701e1951b369>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#生成原始图像\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcontent_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontent_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'content_img' is not defined"
     ]
    }
   ],
   "source": [
    "#生成原始图像\n",
    "input_img = Variable(torch.randn(content_img.data.size())).type(dtype)\n",
    "if use_cuda:\n",
    "    input_img = input_img.cuda()\n",
    "    content_img = content_img.cuda()\n",
    "    style_img = style_img.cuda()\n",
    "    \n",
    "#将选中的待调整图打印出来\n",
    "plt.figure()\n",
    "imshow(input_img.data,title=\"input Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-5becc315c85b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#将输入图像变成神经网络的参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#定义优化器，采用LBFGS优化算法来优化\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLBFGS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_param\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_img' is not defined"
     ]
    }
   ],
   "source": [
    "#将输入图像变成神经网络的参数\n",
    "input_param = nn.Parameter(input_img.data)\n",
    "\n",
    "#定义优化器，采用LBFGS优化算法来优化\n",
    "optimizer = optim.LBFGS([input_param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每一个训练周期\n",
    "#限制输入图像的色彩取值范围在0-1之间\n",
    "input_param.data.clamp_(0,1)\n",
    "\n",
    "#清空梯度\n",
    "optimizer.zero_grad()\n",
    "#将图像输入构造的神经网络中\n",
    "model(input_param)\n",
    "style_score = 0\n",
    "content_score = 0\n",
    "#每个损失函数层都开始反向传播\n",
    "for sl in style_losses:\n",
    "    style_score += sl.backward()\n",
    "    \n",
    "for cl in content_losses:\n",
    "    content_score += cl.backward()\n",
    "    \n",
    "#一步优化(这里看出代码是不完整的，closure是包含上面操作的一个函数def)\n",
    "optimizer.step(closure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#镜像网络，生成对抗网络\n",
    "#生成模型，猫鼠游戏，超分辨率重建，计算机脑补\n",
    "\n",
    "\n",
    "#反卷积，和CNN是镜像的，它的反卷积核和卷积核是上下左右翻转后的关系，就是转置\n",
    "#先是padding把两边用0补齐，然后再和反卷积核做卷积运算\n",
    "\n",
    "#反池化，因为在有stride的卷积操作中当步长大于1的时候也同时会起到池化的作用\n",
    "#所以在反卷积的时候就可以先对原图像进行填补格点来起到反池化的作用\n",
    "\n",
    "#deconvolution，对于生成器来说希望loss越大越好\n",
    "#对于判别器来说希望loss越小越好，所以当loss曲线进入剧烈振荡期的时候，就是在博弈的时候"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-7dbd5cc15421>, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-7dbd5cc15421>\"\u001b[0;36m, line \u001b[0;32m27\u001b[0m\n\u001b[0;31m    for name,module in self.model.named_children():\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "class ModuleG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModuleG,self).__init__()\n",
    "        self.model = nn.Sequential()\n",
    "        #这里参数怎么传暂时还不清楚，尤其是dim的含义，和其他参数的含义\n",
    "        #增加第一层反卷积\n",
    "        self.model.add_module('deconv1',nn.ConvTranspose2d(input_dim,\n",
    "                                    num_features*2,5,2,0,bias=False))\n",
    "        #增加一个batchnorm层\n",
    "        self.model.add_module('bnorm1',nn.BatchNorm2d(num_features*2))\n",
    "        self.model.add_module('relu1',nn.ReLU(True))\n",
    "        \n",
    "        #第二层反卷积\n",
    "        self.model.add_module('deconv2',nn.ConvTranspose2d(num_fetures*2,\n",
    "                                    num_features,5,2,0,bias=False))\n",
    "        self.model.add_module('bnorm2',nn.BatchNorm2d(num_features))\n",
    "        self.model.add_module('relu2',nn.ReLU(True))\n",
    "        \n",
    "        #第三层反卷积\n",
    "        self.model.add_module('deconv3',nn.ConvTranspose2d(num_features,\n",
    "                                             num_chuannels,4,2,0,bias=False))\n",
    "        self.model.add_module('sigmoid',nn.Sigmoid())\n",
    "        \n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = input \n",
    "        for name,module in self.model.named_children():\n",
    "            output = module(output)\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从数据库中读取真实的图片 === 判别器判断 ==== 计算error_real === error_real.backward()\n",
    "#随机产生一个噪声z ==== 生成器产生一组batch的图片 === 判别器判断 === 计算error_fake\n",
    "# ==== error_fake.backward() === optimizerD.step()\n",
    "\n",
    "#Random()<0.5 则继续否则退出  ==== 随机产生噪声z === 学好的生成器产生一组图片 ====\n",
    "#判别器判断  ==== 计算error_G ===== error_G.backward() === optimizerG.step()\n",
    "\n",
    "\n",
    "#1.将真实数据放到辨别网络里识别\n",
    "output = netD(data)  #真实图片\n",
    "\n",
    "#计算损失函数\n",
    "label.data.fill_(1)   #因为是真的所以都是1\n",
    "error_real = criterion(output,label)\n",
    "\n",
    "#2.噪声生成图片\n",
    "noise.data.resize_(data.size()[0], input_dim, 1,1).normal_(0,1)\n",
    "\n",
    "#噪声是一个input_dim维度的向量\n",
    "#喂给生成器生成图像\n",
    "#这里的detach是为了让生成器不参与梯度更新\n",
    "fake_pic = netG(noise).detach()\n",
    "\n",
    "#用辨别器识别假图像\n",
    "output2 = netD(fake_pic)\n",
    "#标签是0，代表图片是伪造得到\n",
    "label.data.fill_(0)\n",
    "\n",
    "#计算损失函数\n",
    "error_fake = criterion(ouput2,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.data.fill(1)  #分类标签全部为1，即真实图像\n",
    "#重新随机生成一个噪声向量\n",
    "noise.data.normal_(0,1)\n",
    "netG.train()\n",
    "#生成器进行伪造\n",
    "fake_pic = netG(noise)\n",
    "\n",
    "#辨别器进行分辨\n",
    "output = netD(fake_pic)\n",
    "#辨别器的损失函数\n",
    "error_G = criterion(ouput,label)\n",
    "\n",
    "#反向传播和优化网络\n",
    "error_G.backward()\n",
    "optimizerG.step()\n",
    "\n",
    "\n",
    "#有一些细节，批正则化，优化算法，反卷积尺寸，网络初始化都忽略了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 接下来是官方教程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接下来是官方教程\n",
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,3)\n",
    "        self.conv2 = nn.Conv2d(6,16,3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*6*6,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        \n",
    "        x = x.view(-1,self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self,x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1109,  0.1164,  0.0358,  0.0668, -0.0648, -0.1617, -0.0863,  0.0604,\n",
      "          0.0627, -0.0568]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1,1,32,32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Linear(in_features=576, out_features=120, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(net.fc1.weight.grad)\n",
    "print(net.fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7fcc00471a58>\n",
      "<AddmmBackward object at 0x7fcc004716a0>\n",
      "<AccumulateGrad object at 0x7fcc00471a58>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0])\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更新权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(1,1,32,32)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1) \n",
    "criterion = nn.MSELoss()                   \n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.01)\n",
    "#清零\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = net(input)\n",
    "loss = criterion(output,target)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[ 0.0488, -0.0451,  0.0227],\n",
       "           [ 0.3286,  0.2313, -0.1646],\n",
       "           [ 0.2145,  0.2534, -0.2652]]],\n",
       " \n",
       " \n",
       "         [[[-0.1296, -0.1138, -0.1765],\n",
       "           [ 0.1043,  0.0154, -0.2794],\n",
       "           [-0.1726, -0.1284, -0.3212]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0771,  0.2457, -0.0671],\n",
       "           [ 0.0678,  0.1519, -0.3046],\n",
       "           [-0.1106,  0.2578,  0.2564]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2772, -0.0563, -0.0297],\n",
       "           [-0.2148,  0.2617, -0.1288],\n",
       "           [-0.0211, -0.2802, -0.0217]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1374, -0.1174, -0.0939],\n",
       "           [ 0.0863, -0.1869, -0.0781],\n",
       "           [ 0.1784,  0.2484,  0.2489]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0495,  0.0908,  0.2680],\n",
       "           [ 0.1280,  0.2069,  0.2212],\n",
       "           [ 0.1324,  0.0902, -0.2895]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2375, -0.1166,  0.0898,  0.1557,  0.2206,  0.0691],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 9.2450e-02,  8.7556e-02,  5.6000e-02],\n",
       "           [-5.7011e-02, -6.2330e-02, -9.0336e-02],\n",
       "           [-1.2348e-02, -1.1423e-01,  1.2134e-01]],\n",
       " \n",
       "          [[ 7.5594e-02, -8.9531e-02, -9.9390e-02],\n",
       "           [ 8.3287e-02,  1.1908e-01,  7.8192e-02],\n",
       "           [ 2.8428e-02,  6.8513e-02,  1.1866e-01]],\n",
       " \n",
       "          [[ 4.6809e-02,  1.8136e-02,  9.9804e-02],\n",
       "           [-2.1465e-02, -6.9645e-02,  5.0744e-02],\n",
       "           [-4.9781e-02, -1.2474e-01,  3.0317e-02]],\n",
       " \n",
       "          [[-1.2900e-01, -4.5200e-03, -2.1806e-02],\n",
       "           [-5.8661e-02, -3.5485e-02,  9.9527e-02],\n",
       "           [-5.1867e-02, -7.8298e-02,  1.8769e-02]],\n",
       " \n",
       "          [[ 9.3649e-03,  1.1879e-01,  7.6051e-02],\n",
       "           [-5.4680e-04,  1.1407e-01,  8.7326e-02],\n",
       "           [ 2.7929e-02,  1.3109e-01, -1.3312e-01]],\n",
       " \n",
       "          [[-8.4907e-02,  7.3118e-03,  1.2768e-01],\n",
       "           [ 1.2950e-01, -4.8361e-02, -1.0224e-02],\n",
       "           [-8.5060e-02,  3.9119e-02,  5.2068e-02]]],\n",
       " \n",
       " \n",
       "         [[[-5.5485e-02, -1.0873e-01, -8.6124e-02],\n",
       "           [-6.3336e-02, -1.3435e-01, -4.1510e-02],\n",
       "           [-5.5524e-02, -9.7689e-02,  1.8847e-03]],\n",
       " \n",
       "          [[-1.1691e-01, -1.1353e-01,  2.1061e-02],\n",
       "           [ 1.3245e-01, -2.7459e-02,  6.7790e-02],\n",
       "           [ 1.1889e-01, -1.0524e-01,  4.3770e-02]],\n",
       " \n",
       "          [[ 5.9584e-02,  1.7360e-02,  1.0561e-01],\n",
       "           [-1.3316e-01,  9.2507e-02,  1.2993e-01],\n",
       "           [ 2.9684e-02, -1.0361e-01,  1.3394e-01]],\n",
       " \n",
       "          [[-6.4065e-02,  6.8762e-03, -9.3757e-02],\n",
       "           [-8.8385e-03, -6.8018e-02, -9.2868e-03],\n",
       "           [-9.5575e-02,  3.8369e-02, -6.8345e-02]],\n",
       " \n",
       "          [[ 4.7277e-03,  1.2244e-01,  5.6091e-02],\n",
       "           [ 5.3315e-02, -4.3483e-02, -1.2499e-01],\n",
       "           [ 6.3574e-02,  7.6734e-02, -9.0451e-02]],\n",
       " \n",
       "          [[-6.5996e-02, -2.7097e-02,  5.4010e-02],\n",
       "           [ 8.8445e-03, -2.0979e-02,  3.7649e-02],\n",
       "           [-3.0546e-03, -9.5858e-02, -1.1235e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 8.1695e-02,  1.0606e-01,  1.1516e-01],\n",
       "           [ 9.3642e-02,  5.1684e-04,  6.1709e-04],\n",
       "           [-9.0588e-02,  9.4961e-02,  7.3288e-02]],\n",
       " \n",
       "          [[ 5.4832e-02, -1.2256e-01, -3.4542e-02],\n",
       "           [-8.1549e-02, -6.0939e-02, -7.0551e-02],\n",
       "           [-2.4783e-02,  8.7587e-02,  1.4307e-02]],\n",
       " \n",
       "          [[ 3.0373e-02,  1.3281e-01, -4.1154e-02],\n",
       "           [-1.0454e-01, -2.3254e-02, -7.8926e-03],\n",
       "           [ 3.9129e-02,  1.2337e-01,  4.4791e-02]],\n",
       " \n",
       "          [[ 7.5166e-02, -9.5013e-02, -9.3785e-02],\n",
       "           [ 1.5858e-02, -3.4304e-02,  7.4114e-03],\n",
       "           [ 3.1942e-02,  9.8000e-02, -1.4556e-02]],\n",
       " \n",
       "          [[-1.1535e-02, -3.9267e-02, -7.9014e-02],\n",
       "           [-1.0607e-01,  8.1527e-02, -4.8212e-02],\n",
       "           [ 1.2403e-01,  6.9903e-02,  8.8044e-05]],\n",
       " \n",
       "          [[ 9.8903e-02,  4.4569e-02, -6.5191e-02],\n",
       "           [ 9.4029e-02,  4.8978e-02, -1.8008e-03],\n",
       "           [ 2.6133e-02,  1.3214e-01, -5.7982e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 5.0425e-02,  1.0001e-01, -7.8671e-02],\n",
       "           [ 1.2408e-01,  1.0467e-01,  1.3246e-01],\n",
       "           [-8.0025e-02,  1.5963e-02, -1.1139e-01]],\n",
       " \n",
       "          [[-1.0550e-01, -2.0483e-02,  1.0886e-01],\n",
       "           [-1.2262e-01,  9.3751e-03,  1.0287e-01],\n",
       "           [-1.0831e-01, -1.2944e-01, -1.0765e-01]],\n",
       " \n",
       "          [[-1.3134e-01,  4.4796e-02,  6.1313e-02],\n",
       "           [ 6.2292e-02,  1.2748e-01, -1.2980e-01],\n",
       "           [-4.5725e-03, -1.2718e-01,  1.2112e-01]],\n",
       " \n",
       "          [[ 5.3525e-02, -6.9357e-02,  3.6426e-02],\n",
       "           [ 2.3769e-02, -1.0849e-01, -4.4737e-02],\n",
       "           [ 7.3511e-02, -3.0755e-02, -9.4362e-02]],\n",
       " \n",
       "          [[-5.8295e-02, -3.0112e-03,  7.0688e-02],\n",
       "           [ 5.8051e-03,  8.7682e-02,  8.0858e-02],\n",
       "           [-8.8247e-02,  1.1020e-01,  1.9409e-02]],\n",
       " \n",
       "          [[ 3.7883e-02,  3.3299e-04, -1.1784e-01],\n",
       "           [-4.9773e-02, -1.0501e-01, -3.2151e-02],\n",
       "           [-8.2383e-02, -1.0939e-01, -1.1463e-01]]],\n",
       " \n",
       " \n",
       "         [[[-4.9745e-02, -8.8126e-03, -3.2626e-02],\n",
       "           [-8.6435e-02,  7.9953e-02, -5.8992e-02],\n",
       "           [-1.0279e-01, -1.3503e-02,  4.9906e-02]],\n",
       " \n",
       "          [[ 1.2335e-01, -1.2169e-01,  1.0479e-01],\n",
       "           [ 2.7516e-02,  2.3796e-02, -8.9953e-03],\n",
       "           [ 1.1756e-02,  1.0034e-01, -7.2171e-02]],\n",
       " \n",
       "          [[-1.1176e-01, -2.9437e-02, -6.5923e-02],\n",
       "           [-4.6326e-02,  6.8094e-02,  1.2160e-01],\n",
       "           [-6.8596e-02, -4.2620e-03,  1.0043e-01]],\n",
       " \n",
       "          [[-3.1313e-02,  7.5946e-03, -5.0648e-02],\n",
       "           [ 7.2533e-02,  1.1339e-01, -5.2730e-02],\n",
       "           [ 1.0830e-01,  1.1031e-01, -6.0517e-02]],\n",
       " \n",
       "          [[-1.0032e-01,  1.0087e-01,  6.0239e-02],\n",
       "           [-9.6513e-02,  8.0555e-02,  6.1434e-02],\n",
       "           [ 9.0094e-02,  1.6650e-02, -8.4272e-02]],\n",
       " \n",
       "          [[ 1.1650e-01,  3.7792e-02,  1.1713e-01],\n",
       "           [ 1.0987e-01, -9.1859e-02, -2.2000e-02],\n",
       "           [ 9.7935e-02,  7.2294e-02,  3.5775e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.3577e-01,  4.0159e-02, -1.3051e-01],\n",
       "           [-1.1288e-01, -2.4466e-02, -1.3344e-01],\n",
       "           [ 8.1622e-02,  3.9138e-02,  4.2442e-02]],\n",
       " \n",
       "          [[-3.0656e-03,  1.0509e-01,  1.6141e-02],\n",
       "           [ 2.3594e-03, -9.5985e-02,  6.9734e-02],\n",
       "           [-1.2671e-01, -4.5189e-02,  4.1787e-02]],\n",
       " \n",
       "          [[ 3.3220e-02,  5.2066e-02, -1.9961e-02],\n",
       "           [ 7.3326e-02,  1.2048e-01, -4.9682e-02],\n",
       "           [-8.0432e-02,  8.9032e-02, -6.3027e-02]],\n",
       " \n",
       "          [[ 4.5231e-02, -1.0802e-01, -2.8608e-03],\n",
       "           [ 1.2073e-01, -3.3159e-02,  7.9046e-02],\n",
       "           [ 4.7380e-02,  3.4948e-02,  8.7798e-02]],\n",
       " \n",
       "          [[-1.3612e-01, -4.7937e-02, -3.9884e-02],\n",
       "           [ 5.7583e-02,  4.3770e-02, -6.0218e-02],\n",
       "           [ 9.0628e-02, -1.6259e-02,  7.9656e-02]],\n",
       " \n",
       "          [[ 5.6605e-02,  4.5834e-02,  9.7352e-03],\n",
       "           [-1.2704e-01, -5.5447e-02,  9.3632e-02],\n",
       "           [-1.1510e-01,  9.6155e-02, -3.5007e-03]]],\n",
       " \n",
       " \n",
       "         [[[ 3.6401e-02,  7.5306e-02, -1.3354e-01],\n",
       "           [ 1.0569e-01,  6.8298e-02, -4.6734e-03],\n",
       "           [-9.0563e-02, -1.2856e-01, -1.1431e-01]],\n",
       " \n",
       "          [[-1.2624e-01,  2.9964e-02, -7.3060e-04],\n",
       "           [-2.1422e-02, -1.0147e-02,  1.1757e-01],\n",
       "           [ 1.2298e-01, -1.2466e-01, -8.9549e-03]],\n",
       " \n",
       "          [[ 9.7684e-02,  4.7976e-03,  1.1961e-01],\n",
       "           [-7.4497e-02, -1.1389e-01, -1.3312e-02],\n",
       "           [-9.6874e-02,  8.4237e-02, -3.9063e-02]],\n",
       " \n",
       "          [[ 7.1335e-02,  2.0104e-02, -3.4029e-05],\n",
       "           [-4.9360e-02, -3.0264e-02,  4.3100e-02],\n",
       "           [ 1.1681e-01, -2.6200e-03, -5.6090e-02]],\n",
       " \n",
       "          [[ 1.3462e-01,  5.3073e-02, -1.6980e-02],\n",
       "           [ 8.0742e-02,  8.2527e-02, -7.4948e-02],\n",
       "           [ 1.2283e-01,  5.2113e-02, -1.1611e-01]],\n",
       " \n",
       "          [[ 4.1185e-03, -6.2686e-02,  8.2038e-04],\n",
       "           [-2.0530e-02, -9.1579e-02,  6.8717e-02],\n",
       "           [-7.3962e-02,  6.4970e-02, -1.3046e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.6788e-02, -6.6139e-02, -1.2582e-01],\n",
       "           [ 1.3096e-01, -7.6622e-02,  6.6637e-02],\n",
       "           [ 4.5802e-02, -3.1801e-02, -3.0340e-02]],\n",
       " \n",
       "          [[ 6.9598e-02, -3.0102e-02,  6.6104e-02],\n",
       "           [-6.7014e-02, -8.1354e-02,  5.3244e-02],\n",
       "           [-3.5525e-02,  8.9684e-02,  5.2140e-02]],\n",
       " \n",
       "          [[ 2.2330e-02, -4.2562e-04, -2.9300e-02],\n",
       "           [ 1.3323e-01,  7.2714e-02, -1.0463e-01],\n",
       "           [-1.1991e-01, -3.6724e-02,  1.1760e-01]],\n",
       " \n",
       "          [[-1.0642e-01, -1.2282e-01,  5.8956e-02],\n",
       "           [ 1.1434e-01,  3.2004e-02, -1.3406e-03],\n",
       "           [ 7.9568e-02,  1.1994e-01,  9.0194e-03]],\n",
       " \n",
       "          [[ 8.6195e-02, -5.4454e-02, -6.1860e-02],\n",
       "           [ 1.1829e-01,  8.0626e-02, -1.0205e-01],\n",
       "           [-1.0303e-01,  6.2503e-02, -6.1182e-03]],\n",
       " \n",
       "          [[ 5.1125e-02,  1.3575e-01, -7.3622e-02],\n",
       "           [ 5.0263e-02, -1.3116e-03, -6.5455e-02],\n",
       "           [ 1.0123e-01, -1.3592e-01, -1.6220e-02]]],\n",
       " \n",
       " \n",
       "         [[[-7.1942e-02, -4.2373e-02, -9.3726e-02],\n",
       "           [-4.7678e-02, -3.1518e-02,  1.0524e-01],\n",
       "           [-9.8720e-02, -4.5341e-02,  6.7447e-02]],\n",
       " \n",
       "          [[ 1.1516e-01,  6.4144e-02, -6.9980e-03],\n",
       "           [-8.8159e-04,  8.4801e-02,  4.5105e-02],\n",
       "           [-1.1937e-01,  1.3002e-01,  1.8711e-02]],\n",
       " \n",
       "          [[-1.1282e-01, -1.2323e-01,  2.4454e-02],\n",
       "           [ 1.1262e-01,  9.5836e-02,  9.7202e-03],\n",
       "           [ 1.0108e-01, -4.1598e-02,  3.6975e-03]],\n",
       " \n",
       "          [[-7.1853e-03,  1.0612e-01,  4.3361e-02],\n",
       "           [ 5.8687e-02, -5.4710e-02,  1.6754e-02],\n",
       "           [-1.2615e-01, -7.5908e-02, -6.1691e-02]],\n",
       " \n",
       "          [[ 1.7287e-02,  1.0681e-01,  1.2367e-02],\n",
       "           [ 5.8403e-02,  4.8083e-02,  3.2819e-02],\n",
       "           [-5.9110e-02, -9.3847e-02,  6.9527e-02]],\n",
       " \n",
       "          [[ 1.0786e-01,  2.8347e-02,  4.6962e-02],\n",
       "           [ 1.1984e-01, -4.5937e-02, -2.3742e-03],\n",
       "           [ 9.9335e-02, -9.4793e-03, -5.6476e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.0690e-02,  4.4232e-02,  9.9187e-02],\n",
       "           [-1.2768e-01,  1.4238e-02,  1.2447e-01],\n",
       "           [ 3.1497e-02,  9.2632e-02,  6.9479e-02]],\n",
       " \n",
       "          [[ 9.2418e-02,  7.2998e-02, -1.2969e-01],\n",
       "           [-2.6865e-02, -2.1912e-02, -1.3123e-01],\n",
       "           [ 3.0576e-02,  1.1516e-02,  1.0598e-02]],\n",
       " \n",
       "          [[-9.0253e-02,  1.3182e-01,  2.8565e-02],\n",
       "           [ 1.0273e-01, -7.0546e-03,  1.0322e-01],\n",
       "           [ 1.2636e-01, -3.1009e-02, -8.3765e-02]],\n",
       " \n",
       "          [[-8.9430e-03, -1.6020e-02,  6.8173e-02],\n",
       "           [-1.0272e-01,  1.3061e-01,  6.1159e-02],\n",
       "           [ 3.6903e-02,  7.9439e-02, -5.2745e-02]],\n",
       " \n",
       "          [[-7.0359e-02,  7.2820e-02, -5.9891e-02],\n",
       "           [ 2.1249e-02,  1.0589e-01, -1.0217e-01],\n",
       "           [-9.8242e-02,  8.9855e-02, -7.3023e-02]],\n",
       " \n",
       "          [[-9.1759e-02, -8.5336e-02, -6.5265e-02],\n",
       "           [-1.0086e-01,  9.9348e-02, -7.7256e-02],\n",
       "           [-3.4222e-02,  1.0828e-01,  1.1028e-01]]],\n",
       " \n",
       " \n",
       "         [[[-9.9999e-02,  9.3825e-02, -4.9169e-02],\n",
       "           [ 6.6950e-02, -1.2946e-01, -3.3210e-02],\n",
       "           [ 8.1909e-02,  8.4766e-02,  2.5540e-02]],\n",
       " \n",
       "          [[-8.4022e-02, -9.3024e-02,  6.8673e-02],\n",
       "           [ 1.0224e-01, -5.3601e-02, -4.2352e-02],\n",
       "           [-1.2965e-01, -4.3719e-02,  8.6072e-02]],\n",
       " \n",
       "          [[ 4.0493e-02,  2.7267e-02,  1.3120e-01],\n",
       "           [-1.0242e-03, -1.1146e-01,  3.1407e-02],\n",
       "           [-6.7613e-02, -1.2900e-01,  7.9495e-02]],\n",
       " \n",
       "          [[ 1.7135e-03, -3.7760e-02, -2.3614e-02],\n",
       "           [ 3.4572e-02,  9.6967e-02,  2.0248e-02],\n",
       "           [-1.2524e-01, -5.7624e-02, -5.3803e-02]],\n",
       " \n",
       "          [[ 4.2122e-02, -3.2928e-02, -7.8919e-02],\n",
       "           [-3.1569e-02,  5.8840e-02,  1.1041e-01],\n",
       "           [ 5.2207e-02, -1.2186e-01,  2.8202e-02]],\n",
       " \n",
       "          [[ 5.0553e-02, -1.1965e-01,  4.2069e-02],\n",
       "           [-7.2464e-02,  1.3404e-01, -1.3543e-01],\n",
       "           [ 1.2087e-01,  7.8549e-02, -7.3466e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.3538e-02, -3.8312e-02, -6.2195e-02],\n",
       "           [ 9.1967e-02, -6.4643e-02,  6.2884e-02],\n",
       "           [-1.2927e-02,  2.7164e-02,  6.6373e-02]],\n",
       " \n",
       "          [[-1.0829e-01, -1.0608e-01, -1.0123e-01],\n",
       "           [ 1.2346e-01, -1.3239e-02, -3.6270e-02],\n",
       "           [-1.1479e-01,  1.2329e-01,  5.2093e-02]],\n",
       " \n",
       "          [[-8.7625e-02,  1.4048e-02,  1.1326e-01],\n",
       "           [ 1.0001e-01, -9.2080e-02, -1.2827e-02],\n",
       "           [-9.2445e-02, -8.1826e-02,  1.0577e-01]],\n",
       " \n",
       "          [[ 2.5991e-02,  2.1230e-02, -4.4676e-02],\n",
       "           [ 1.5320e-02, -1.5302e-02,  9.7198e-02],\n",
       "           [-1.0076e-01,  2.4072e-02, -3.1887e-03]],\n",
       " \n",
       "          [[-8.2469e-02, -5.6139e-02, -2.3213e-03],\n",
       "           [ 1.0521e-01, -1.1593e-01,  1.2787e-03],\n",
       "           [-4.2731e-02,  8.5446e-02,  4.7469e-02]],\n",
       " \n",
       "          [[ 1.3347e-01,  4.0967e-03,  1.6882e-02],\n",
       "           [ 9.1496e-02, -6.1786e-03,  9.8392e-02],\n",
       "           [-3.8758e-02, -6.5367e-02,  2.9568e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 9.4004e-03,  7.4067e-03, -9.1532e-02],\n",
       "           [-3.6102e-02, -7.2768e-02,  1.1191e-01],\n",
       "           [ 3.2696e-02, -1.3425e-01, -6.7325e-02]],\n",
       " \n",
       "          [[-4.3717e-02, -4.5561e-02, -4.8004e-02],\n",
       "           [-1.0952e-01,  1.1584e-01,  8.1784e-02],\n",
       "           [-8.1614e-02,  3.2506e-02,  6.7634e-02]],\n",
       " \n",
       "          [[ 1.2609e-01,  8.5995e-02,  1.2559e-01],\n",
       "           [-1.2172e-02,  4.4003e-02, -4.1417e-02],\n",
       "           [-4.5387e-02, -1.3105e-01, -1.0264e-01]],\n",
       " \n",
       "          [[ 1.2919e-01, -2.1278e-02,  1.2874e-01],\n",
       "           [-7.2544e-02, -7.8405e-02, -1.4414e-02],\n",
       "           [-1.0368e-01,  6.6432e-03,  7.0094e-02]],\n",
       " \n",
       "          [[-8.9288e-02, -3.8111e-02,  4.3660e-02],\n",
       "           [-4.1831e-02, -4.1224e-02, -2.0354e-02],\n",
       "           [-5.6910e-02,  1.1429e-01,  5.8453e-02]],\n",
       " \n",
       "          [[-3.2797e-02, -1.2557e-01, -7.4609e-02],\n",
       "           [-1.5579e-02, -4.1313e-02,  6.1930e-02],\n",
       "           [-7.0044e-03, -5.0729e-02, -1.0252e-01]]],\n",
       " \n",
       " \n",
       "         [[[-6.1252e-02, -9.5301e-02,  1.3541e-01],\n",
       "           [ 4.9468e-02, -6.4158e-02, -1.5144e-02],\n",
       "           [-4.1896e-02, -2.9900e-02, -6.1871e-02]],\n",
       " \n",
       "          [[ 1.2066e-01, -4.9632e-02,  5.4112e-02],\n",
       "           [ 3.8891e-02,  5.6172e-02,  8.3120e-02],\n",
       "           [-2.9771e-02,  7.9570e-02,  6.4290e-02]],\n",
       " \n",
       "          [[ 4.5179e-02, -1.4704e-02,  4.7533e-02],\n",
       "           [ 4.1208e-02, -8.6762e-02, -6.9271e-02],\n",
       "           [-5.0505e-02,  1.8176e-02,  7.1741e-03]],\n",
       " \n",
       "          [[ 3.7261e-02,  1.2207e-01,  8.1021e-02],\n",
       "           [ 3.1458e-02, -8.0670e-02,  9.9702e-02],\n",
       "           [ 7.4933e-02, -1.1579e-01, -1.1068e-01]],\n",
       " \n",
       "          [[ 5.4452e-02,  9.2983e-02, -5.1625e-02],\n",
       "           [ 1.0411e-04, -8.4842e-02, -2.6860e-02],\n",
       "           [-7.8831e-03, -7.1167e-02, -1.0956e-01]],\n",
       " \n",
       "          [[ 1.3416e-01, -1.0405e-01,  6.6981e-02],\n",
       "           [ 1.3035e-01,  8.7909e-02,  7.4026e-02],\n",
       "           [-4.4677e-02,  3.0523e-02, -9.4438e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.0052e-01,  1.5022e-02,  9.4341e-02],\n",
       "           [-9.4487e-02,  2.1908e-02, -3.6836e-03],\n",
       "           [-1.7019e-02, -7.0132e-02, -8.1521e-02]],\n",
       " \n",
       "          [[-3.9319e-02,  9.2262e-03,  5.2220e-02],\n",
       "           [ 4.5776e-02, -6.8497e-02,  9.1737e-02],\n",
       "           [-1.2950e-01, -4.0436e-02, -7.7828e-02]],\n",
       " \n",
       "          [[ 7.0268e-02,  5.4537e-02,  1.1921e-01],\n",
       "           [ 1.3617e-02,  3.2263e-02, -1.3797e-03],\n",
       "           [ 9.7075e-02, -1.3192e-02, -6.0819e-02]],\n",
       " \n",
       "          [[-4.8596e-02, -5.5262e-02,  7.2110e-03],\n",
       "           [ 8.3515e-02, -7.4656e-02, -5.0635e-03],\n",
       "           [-1.8125e-02,  8.9733e-02,  1.7559e-02]],\n",
       " \n",
       "          [[ 1.0882e-01, -8.1815e-02,  8.4718e-02],\n",
       "           [ 1.0166e-01,  1.1258e-01, -1.2653e-01],\n",
       "           [-8.0604e-02, -3.9967e-02,  1.2309e-01]],\n",
       " \n",
       "          [[-2.5235e-02,  2.8112e-03,  1.1153e-01],\n",
       "           [-8.7814e-02,  3.1944e-02,  5.4206e-02],\n",
       "           [ 6.6298e-02,  4.2976e-02, -1.3559e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.3530e-01,  1.3458e-01, -1.3134e-01],\n",
       "           [ 7.2357e-02,  6.7787e-02, -1.1614e-01],\n",
       "           [ 8.2076e-02, -3.0646e-02, -1.2691e-01]],\n",
       " \n",
       "          [[-4.3550e-02, -9.9257e-02, -1.2185e-01],\n",
       "           [-5.8872e-02,  1.0836e-01,  2.9832e-02],\n",
       "           [-1.1098e-01,  3.8483e-02,  5.7508e-02]],\n",
       " \n",
       "          [[-7.1646e-02, -6.3545e-02,  8.0297e-02],\n",
       "           [-1.0426e-01, -9.3629e-03, -9.7021e-02],\n",
       "           [ 1.0886e-01, -6.3327e-02, -1.3256e-02]],\n",
       " \n",
       "          [[ 3.9259e-03, -1.0272e-01,  3.8640e-02],\n",
       "           [ 3.1932e-02,  1.2601e-01, -1.0729e-01],\n",
       "           [ 2.0492e-02, -1.2138e-01, -2.9149e-02]],\n",
       " \n",
       "          [[ 6.7644e-02, -9.4548e-02,  1.2027e-01],\n",
       "           [ 9.4394e-02,  9.3499e-02,  1.3030e-01],\n",
       "           [ 1.0890e-01,  1.0796e-01, -8.4760e-02]],\n",
       " \n",
       "          [[ 5.2679e-02,  4.9025e-02,  9.8410e-03],\n",
       "           [ 1.0583e-01,  1.1071e-02,  8.3026e-02],\n",
       "           [-1.0336e-01, -5.5013e-02, -1.0512e-01]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0836, -0.0755,  0.1115, -0.1288,  0.0325, -0.0377, -0.0940,  0.0013,\n",
       "         -0.0377,  0.0187, -0.0626, -0.1106,  0.1334,  0.0724, -0.0127, -0.0396],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0088,  0.0133, -0.0102,  ..., -0.0190,  0.0160,  0.0120],\n",
       "         [-0.0243,  0.0295,  0.0233,  ..., -0.0028,  0.0097, -0.0411],\n",
       "         [-0.0241,  0.0331, -0.0262,  ..., -0.0156, -0.0192,  0.0054],\n",
       "         ...,\n",
       "         [-0.0344, -0.0143,  0.0159,  ...,  0.0105,  0.0164, -0.0056],\n",
       "         [-0.0401, -0.0306,  0.0364,  ...,  0.0060, -0.0160,  0.0414],\n",
       "         [ 0.0021, -0.0033, -0.0014,  ...,  0.0132, -0.0011, -0.0119]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0034,  0.0378, -0.0143, -0.0409, -0.0242, -0.0027,  0.0224, -0.0405,\n",
       "          0.0034,  0.0174,  0.0309,  0.0074,  0.0118,  0.0215, -0.0291, -0.0120,\n",
       "          0.0165,  0.0009,  0.0226, -0.0032,  0.0107, -0.0365,  0.0058,  0.0067,\n",
       "         -0.0090,  0.0228,  0.0199,  0.0414,  0.0073,  0.0320,  0.0186, -0.0065,\n",
       "          0.0373, -0.0206,  0.0336,  0.0283,  0.0088, -0.0045,  0.0096, -0.0044,\n",
       "         -0.0348,  0.0231, -0.0344, -0.0272, -0.0028, -0.0404,  0.0245, -0.0384,\n",
       "          0.0235, -0.0300, -0.0054,  0.0014, -0.0144,  0.0152, -0.0112, -0.0295,\n",
       "          0.0130,  0.0360,  0.0363, -0.0041, -0.0084,  0.0254, -0.0028, -0.0140,\n",
       "          0.0273, -0.0155,  0.0135, -0.0147,  0.0255,  0.0275, -0.0361, -0.0103,\n",
       "         -0.0060,  0.0199,  0.0353,  0.0016,  0.0047, -0.0328,  0.0215,  0.0029,\n",
       "         -0.0263, -0.0181, -0.0216, -0.0026,  0.0019,  0.0178,  0.0322,  0.0201,\n",
       "          0.0024, -0.0337,  0.0291,  0.0331,  0.0178, -0.0037, -0.0065,  0.0179,\n",
       "          0.0027,  0.0328,  0.0159,  0.0238, -0.0005,  0.0065, -0.0289, -0.0246,\n",
       "          0.0147, -0.0373, -0.0396, -0.0222,  0.0252,  0.0403, -0.0401,  0.0261,\n",
       "         -0.0240, -0.0377, -0.0292, -0.0292, -0.0200, -0.0031,  0.0281,  0.0115],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0555, -0.0642,  0.0350,  ..., -0.0474, -0.0353,  0.0679],\n",
       "         [ 0.0462, -0.0006, -0.0730,  ...,  0.0695,  0.0706, -0.0183],\n",
       "         [ 0.0365,  0.0859,  0.0794,  ...,  0.0554,  0.0774, -0.0016],\n",
       "         ...,\n",
       "         [-0.0809,  0.0607, -0.0162,  ..., -0.0790,  0.0908,  0.0137],\n",
       "         [-0.0420, -0.0146,  0.0429,  ..., -0.0268, -0.0790, -0.0245],\n",
       "         [-0.0289,  0.0655,  0.0467,  ..., -0.0017, -0.0165,  0.0718]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0109,  0.0099,  0.0040, -0.0026, -0.0398,  0.0408,  0.0135,  0.0827,\n",
       "         -0.0853,  0.0701,  0.0593, -0.0689, -0.0032, -0.0712, -0.0787,  0.0297,\n",
       "         -0.0257,  0.0621,  0.0142, -0.0055, -0.0555,  0.0305,  0.0747, -0.0409,\n",
       "         -0.0199, -0.0266, -0.0576, -0.0335,  0.0139, -0.0588,  0.0489,  0.0558,\n",
       "         -0.0012, -0.0854, -0.0429, -0.0403, -0.0884,  0.0631, -0.0185, -0.0903,\n",
       "          0.0692, -0.0167, -0.0589, -0.0541,  0.0372,  0.0815, -0.0458, -0.0694,\n",
       "         -0.0183,  0.0803, -0.0301, -0.0879, -0.0713, -0.0441, -0.0683,  0.0821,\n",
       "         -0.0261, -0.0331,  0.0795,  0.0805,  0.0380,  0.0331,  0.0776, -0.0189,\n",
       "         -0.0639,  0.0139, -0.0283, -0.0132, -0.0044,  0.0788,  0.0588, -0.0108,\n",
       "          0.0554, -0.0006, -0.0895, -0.0876, -0.0561, -0.0847, -0.0361,  0.0900,\n",
       "         -0.0442, -0.0278, -0.0005, -0.0533], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-1.0809e-01,  7.3898e-02,  1.0266e-01,  2.5363e-02,  1.0623e-01,\n",
       "          -2.4730e-02,  4.4160e-02, -1.5723e-02,  9.2162e-02, -6.4100e-02,\n",
       "          -4.1485e-02,  4.1640e-02, -7.8595e-02, -1.9786e-02,  1.6063e-02,\n",
       "          -3.7450e-03,  1.0726e-01, -5.8002e-02,  5.5632e-02,  1.0078e-01,\n",
       "          -1.0799e-01,  4.0256e-02,  7.5452e-02,  9.8303e-02, -9.8688e-02,\n",
       "           5.1067e-02, -9.3888e-03,  3.4736e-04,  2.7839e-03, -4.0767e-02,\n",
       "           5.4656e-02,  2.6321e-02,  6.2095e-02, -6.1143e-02, -3.3012e-03,\n",
       "          -8.4860e-02, -3.3237e-02, -8.4370e-02, -4.6869e-02,  3.6591e-03,\n",
       "          -5.2786e-02,  1.0392e-01,  2.9827e-02, -9.5111e-02,  8.7822e-02,\n",
       "          -8.1662e-03,  8.6834e-03,  1.9093e-02, -5.9663e-03, -6.7988e-02,\n",
       "          -1.3778e-02,  3.7314e-02, -5.4909e-02,  1.0269e-01,  2.7505e-02,\n",
       "           5.9121e-02, -3.4864e-02,  3.5489e-02, -8.7106e-02,  1.0915e-01,\n",
       "           1.7481e-02,  4.0724e-02,  2.3949e-03,  4.3001e-02, -1.6926e-02,\n",
       "           6.5723e-02, -8.4676e-02,  3.3472e-02,  2.7094e-02, -1.9589e-02,\n",
       "          -2.0297e-02, -8.9033e-02,  3.3553e-02, -9.8843e-02, -4.1975e-02,\n",
       "           1.5508e-02, -8.0911e-02, -2.5830e-02,  5.6108e-02,  4.0720e-02,\n",
       "           1.0122e-02, -2.9765e-02,  8.7958e-02, -1.8744e-03],\n",
       "         [ 1.0395e-01, -8.1642e-02,  7.6702e-02, -9.0682e-02, -8.3136e-02,\n",
       "           8.4821e-02, -5.7208e-02, -5.7185e-02, -4.4346e-02, -7.5331e-02,\n",
       "          -8.7271e-02, -1.0336e-01,  4.7858e-02, -2.4378e-02, -1.0745e-01,\n",
       "          -3.0269e-02, -3.8961e-02, -2.2621e-02,  4.0408e-03, -7.1565e-02,\n",
       "          -1.6742e-03,  7.7964e-02,  1.9870e-02, -8.0852e-02,  8.7749e-03,\n",
       "           2.5227e-02, -1.5131e-02,  4.3127e-02, -2.8211e-02,  6.5420e-03,\n",
       "           1.0472e-01,  3.9555e-02,  6.1922e-02,  3.6128e-02,  6.1871e-02,\n",
       "           3.4190e-02, -9.5661e-03, -9.5629e-04,  8.6597e-02, -1.1799e-02,\n",
       "           4.4583e-02, -1.0655e-01,  9.7425e-02, -2.3000e-02, -2.7530e-02,\n",
       "          -9.7432e-02, -1.1917e-02,  5.6875e-02,  6.2770e-03, -6.0006e-02,\n",
       "           3.8062e-02, -3.2861e-02, -8.9939e-02,  8.2668e-02,  3.8256e-02,\n",
       "           5.4987e-02,  5.1305e-02, -8.7117e-02,  3.0036e-02, -4.3614e-02,\n",
       "          -1.1280e-02, -8.2187e-02, -2.8476e-02,  5.9445e-02, -5.4634e-02,\n",
       "          -1.0432e-02, -4.9892e-02, -6.5330e-02,  8.9773e-02, -8.8058e-02,\n",
       "           5.2830e-02, -8.9755e-02,  2.2320e-02,  4.1166e-02, -8.2771e-02,\n",
       "           2.6514e-02,  4.9697e-02, -5.1295e-02,  9.7504e-02,  3.0131e-02,\n",
       "          -6.4477e-02,  1.0907e-01, -3.4616e-02, -8.1097e-03],\n",
       "         [ 4.5318e-02, -5.2332e-02,  5.9080e-02, -1.1489e-02,  5.1459e-04,\n",
       "          -5.6221e-02,  6.8230e-02, -3.6368e-02, -5.2468e-02,  3.6387e-02,\n",
       "           5.9796e-02, -1.0858e-01,  1.0397e-01, -4.5336e-02,  6.3754e-02,\n",
       "           5.7621e-02,  8.1575e-02, -1.3721e-03, -3.7643e-02, -5.1221e-02,\n",
       "          -4.4870e-02, -7.3283e-02, -1.3516e-02, -8.0862e-02, -5.8533e-02,\n",
       "          -6.3439e-02,  1.0821e-01, -2.3604e-02,  1.0173e-01, -2.0514e-02,\n",
       "          -6.2083e-02, -4.0271e-02, -4.9595e-02,  3.4870e-02, -7.6021e-04,\n",
       "           1.0293e-01,  1.5283e-04,  8.0783e-02,  8.1916e-02, -9.6554e-02,\n",
       "           2.2754e-02,  5.8415e-02,  5.7427e-02, -5.0113e-02, -7.9839e-02,\n",
       "          -1.2719e-04,  1.0221e-01, -7.6594e-02,  7.0480e-02, -6.9377e-02,\n",
       "           3.7117e-02,  1.5716e-02, -4.9785e-02, -4.9269e-02,  2.2681e-02,\n",
       "           5.8632e-03, -7.5637e-02,  5.7426e-02,  2.7516e-03,  3.1827e-02,\n",
       "          -1.6376e-02,  3.1282e-02,  9.6447e-03, -9.1457e-03,  8.4789e-02,\n",
       "           6.0719e-02, -2.6473e-02, -2.3411e-02,  3.5263e-02,  1.0723e-01,\n",
       "           9.7551e-02, -3.1631e-02,  3.8604e-02, -9.0415e-03, -7.4017e-02,\n",
       "           1.6449e-02, -2.7537e-02, -9.3313e-02, -8.6582e-02,  3.8368e-02,\n",
       "          -6.6723e-02,  5.8626e-02,  5.6197e-02, -4.8835e-02],\n",
       "         [-5.8848e-02,  3.1478e-02,  4.7201e-02,  1.4173e-02,  2.1250e-02,\n",
       "           1.1182e-02,  4.1522e-02,  2.5238e-02, -4.5393e-02, -9.1308e-03,\n",
       "           4.8786e-02,  7.2758e-03,  1.3629e-02,  1.0865e-02,  2.4032e-02,\n",
       "           8.6900e-02, -1.0406e-01, -1.5277e-02,  7.1507e-02,  3.5831e-02,\n",
       "           7.3754e-02,  3.7800e-02, -2.6071e-02,  7.9389e-02,  2.9999e-02,\n",
       "          -6.8183e-02, -3.0490e-02,  3.2646e-03, -9.2422e-02, -3.7422e-02,\n",
       "          -2.4069e-02,  9.7475e-02, -9.5538e-02,  7.5682e-02,  7.9922e-02,\n",
       "          -9.8358e-02, -7.2474e-02, -1.0247e-01, -6.2397e-02,  8.6085e-02,\n",
       "          -3.4863e-02, -3.0421e-02,  4.8634e-02, -6.6021e-02,  9.9851e-02,\n",
       "           8.0820e-02,  5.6616e-03,  9.7124e-02, -1.8183e-02,  2.1077e-02,\n",
       "          -1.1518e-02,  4.2971e-02, -7.0666e-03,  9.6301e-02,  3.7989e-02,\n",
       "           7.2758e-02,  9.2127e-02,  1.8274e-02,  9.4137e-02,  4.8516e-02,\n",
       "          -3.6705e-02, -1.0221e-01,  2.5695e-02, -9.4507e-02, -7.4402e-02,\n",
       "          -5.7477e-02, -5.8259e-02, -6.0202e-02,  1.0665e-01,  8.3408e-02,\n",
       "           8.5849e-02,  7.5348e-02, -1.0130e-01,  9.0345e-02,  1.7313e-02,\n",
       "          -1.6744e-02,  8.2750e-02,  5.6327e-02,  4.6741e-02,  1.0169e-01,\n",
       "           9.8038e-02, -1.5860e-02,  9.2522e-02, -1.0605e-01],\n",
       "         [-6.0544e-02, -1.0676e-01,  9.6603e-02, -2.0420e-02,  1.6725e-02,\n",
       "           2.9251e-02, -9.2098e-02, -5.9117e-02, -8.6601e-02, -5.9363e-02,\n",
       "          -1.0515e-01,  1.3960e-03, -2.1219e-02, -8.3507e-02, -9.7807e-02,\n",
       "          -1.9686e-02, -8.1902e-02,  3.2130e-02,  4.6276e-02,  4.4185e-03,\n",
       "          -6.2414e-02, -4.5771e-02,  9.2749e-02,  4.7250e-02,  4.5712e-02,\n",
       "           1.7047e-02,  1.2816e-02, -3.9310e-02,  2.1678e-02,  5.6792e-02,\n",
       "          -7.5770e-02, -4.2445e-02, -1.0659e-01, -1.0590e-01, -1.0061e-01,\n",
       "          -7.6772e-02, -6.8182e-02, -7.3379e-02, -8.4030e-02, -3.0739e-02,\n",
       "           8.5624e-02,  1.8184e-02, -2.9485e-03,  7.8367e-02,  6.7660e-03,\n",
       "           5.8059e-02, -4.2132e-02,  4.5892e-02,  5.1256e-02,  6.2801e-02,\n",
       "           2.6083e-02,  1.8348e-02, -1.0020e-01,  6.3474e-02, -2.2504e-02,\n",
       "           3.9261e-02,  1.0895e-04, -1.0051e-01, -1.5377e-02, -8.8886e-02,\n",
       "           8.0789e-02, -2.4424e-03, -7.4020e-02, -6.6518e-02, -1.8264e-02,\n",
       "           8.0513e-02,  5.7186e-02, -5.7707e-02, -7.6110e-02, -1.0092e-01,\n",
       "           6.5073e-02,  7.8735e-02, -6.8098e-02,  4.9342e-02,  5.1884e-02,\n",
       "           9.6575e-02,  6.8010e-02,  5.3196e-02,  8.8240e-02,  1.5622e-02,\n",
       "           1.2197e-02,  4.3549e-02,  6.0874e-02,  9.2983e-02],\n",
       "         [-3.2082e-02, -4.4971e-02,  1.0667e-01, -5.6872e-02, -2.0848e-02,\n",
       "           6.1065e-02, -1.5752e-02,  2.4789e-02, -1.0231e-01,  3.7459e-02,\n",
       "          -6.7103e-02, -3.3000e-02,  4.1447e-02, -8.5647e-02,  1.0678e-02,\n",
       "           1.0161e-02,  6.7106e-02, -3.9616e-02, -1.7151e-02,  4.2843e-02,\n",
       "           2.9639e-02,  5.8443e-02,  6.3090e-02, -7.1488e-02, -1.0730e-01,\n",
       "           1.6677e-03, -7.6305e-02, -1.6349e-02, -3.7604e-02,  7.5354e-02,\n",
       "          -8.4912e-02,  9.0005e-02, -1.8676e-02,  2.2128e-02, -6.6157e-02,\n",
       "          -4.1976e-04,  3.1758e-02, -6.7347e-02, -6.2203e-03, -4.0997e-02,\n",
       "          -9.9930e-02, -7.4488e-02,  8.8896e-03, -5.6003e-02,  3.6978e-02,\n",
       "          -3.8538e-02,  4.7341e-02, -8.1144e-02,  4.4277e-02,  9.4037e-03,\n",
       "           2.3131e-02, -6.1462e-02, -6.4094e-02, -1.0174e-01, -3.2558e-02,\n",
       "          -5.5755e-02, -7.7916e-02,  2.8832e-02, -4.9224e-02,  2.7364e-02,\n",
       "          -8.3222e-02, -7.0970e-02, -9.1000e-02, -1.0404e-01,  8.1575e-02,\n",
       "          -1.5591e-02,  5.8259e-02,  1.8541e-02,  3.5957e-02,  5.5145e-02,\n",
       "          -5.5743e-02,  1.9409e-02, -1.0008e-01, -8.7473e-02, -8.8839e-02,\n",
       "           5.9715e-02,  2.2717e-02, -2.2878e-02, -4.3414e-02,  8.7902e-02,\n",
       "           9.8047e-02,  6.4526e-03, -4.8618e-03, -1.0808e-01],\n",
       "         [ 9.9010e-02,  3.4197e-02, -5.9061e-02,  1.2894e-02,  2.8267e-02,\n",
       "           3.9495e-02, -8.6070e-02, -1.0445e-01, -8.1853e-02, -5.4630e-02,\n",
       "           3.1161e-02, -2.9877e-02, -5.9233e-02, -2.7431e-02,  6.1358e-02,\n",
       "           8.0163e-02, -5.4867e-02, -1.0543e-01,  2.2243e-02,  9.8878e-03,\n",
       "           1.4835e-02, -5.2642e-02,  9.7060e-02,  5.4259e-02,  2.0103e-02,\n",
       "          -5.7985e-03, -7.9783e-02,  5.0244e-02, -9.0695e-02,  9.1863e-02,\n",
       "          -6.8544e-02, -9.8213e-02, -5.3209e-02,  4.2875e-02, -1.0573e-01,\n",
       "           5.8748e-02,  1.4902e-02,  5.7560e-02, -3.2328e-02, -4.5411e-02,\n",
       "           5.0535e-02,  1.0133e-01,  1.0470e-01, -1.8276e-02, -1.0758e-01,\n",
       "           7.4180e-02, -7.6160e-02,  8.8300e-02, -9.3537e-02,  4.9664e-02,\n",
       "          -8.5665e-02,  8.8957e-02, -7.1832e-02, -8.9908e-02, -6.9405e-02,\n",
       "           9.6124e-03,  8.9250e-02,  2.1463e-02, -4.9546e-03,  1.0276e-01,\n",
       "          -4.0147e-02, -8.9939e-02, -9.0681e-02,  3.3167e-02,  6.9605e-02,\n",
       "          -8.5209e-02,  3.0213e-02,  2.2797e-03,  4.8857e-04, -7.9539e-02,\n",
       "           7.1309e-02,  2.5593e-03, -5.9956e-02,  7.0785e-02,  4.8788e-03,\n",
       "          -5.6957e-02,  1.9289e-03, -3.6959e-02, -8.6823e-02, -6.1327e-02,\n",
       "           1.0097e-01,  1.0404e-01,  6.1804e-02,  9.7419e-02],\n",
       "         [-2.3984e-02,  6.3966e-02, -1.0038e-01,  2.9217e-02,  1.7370e-02,\n",
       "           9.1740e-02, -4.6623e-02, -1.3123e-02,  6.1284e-02,  5.4604e-02,\n",
       "           4.5986e-02,  8.9031e-02,  6.7057e-02, -2.8058e-02, -6.4247e-02,\n",
       "           1.5828e-02,  7.1922e-02, -8.0790e-02, -6.0569e-02, -6.9009e-02,\n",
       "          -1.3521e-02, -6.7188e-02,  8.0153e-02,  1.3491e-02, -5.4268e-02,\n",
       "           2.9537e-03, -4.3988e-02, -4.5667e-02,  1.6077e-02, -8.8487e-03,\n",
       "           3.1918e-02,  9.8691e-02,  9.6186e-02,  9.5377e-03,  3.0086e-02,\n",
       "           1.2958e-02, -6.5521e-02,  9.3277e-02,  8.1907e-02, -4.1526e-02,\n",
       "           5.3839e-02, -4.1960e-02,  1.7877e-02,  1.7643e-02,  1.8392e-02,\n",
       "          -1.2276e-02, -4.4873e-02,  6.4027e-02, -3.7315e-02, -3.1828e-02,\n",
       "           9.2342e-02,  5.5237e-03,  2.6909e-02, -6.6301e-02, -8.3069e-02,\n",
       "          -1.4453e-02, -7.6926e-02, -1.6788e-02,  7.7635e-02,  6.9703e-02,\n",
       "          -3.3438e-02, -2.1357e-02, -7.3781e-02, -9.5072e-02, -9.9502e-03,\n",
       "          -1.2379e-02,  9.7112e-04, -1.6743e-02, -9.7412e-02,  5.0565e-02,\n",
       "           1.0589e-01,  1.0056e-01,  3.1438e-02, -1.7826e-02, -3.4826e-02,\n",
       "           1.7048e-02, -4.6424e-04, -6.1889e-02, -6.1267e-02, -2.0235e-03,\n",
       "           7.1536e-02,  1.3672e-02, -8.1668e-02, -1.5382e-02],\n",
       "         [-5.2129e-02,  7.5455e-02, -4.7491e-02,  1.0521e-01, -8.5727e-02,\n",
       "          -3.9194e-02, -4.8360e-02, -9.9030e-02, -1.9420e-02,  6.5633e-02,\n",
       "          -1.0789e-01, -1.3489e-02, -6.5667e-02, -5.1502e-02, -3.6728e-02,\n",
       "           4.1265e-02,  8.4277e-02,  3.5504e-02,  1.0689e-01, -1.1133e-02,\n",
       "          -3.7993e-02,  9.2543e-02,  5.7439e-02,  2.1090e-02,  8.0742e-02,\n",
       "           2.1603e-02, -8.6492e-02,  8.8331e-02, -8.0729e-03,  9.0160e-02,\n",
       "          -7.5202e-02,  3.7251e-02,  1.0428e-01,  7.8459e-02,  9.1941e-02,\n",
       "           6.9188e-02,  6.1722e-03, -9.5508e-02,  4.6290e-02, -5.8817e-02,\n",
       "          -3.3278e-02, -9.4320e-02, -8.2655e-02, -8.0576e-02,  6.0889e-02,\n",
       "           4.9794e-02, -4.4041e-02,  5.9870e-02, -5.5120e-02,  5.5573e-02,\n",
       "           1.0648e-01,  1.5860e-03,  7.6315e-02,  4.8849e-02,  1.0512e-02,\n",
       "          -5.9164e-02, -9.0327e-02, -6.5813e-02,  7.5528e-02,  5.3733e-02,\n",
       "           7.6664e-02,  5.9738e-02,  9.1205e-02, -6.2758e-02,  7.8636e-02,\n",
       "          -2.6725e-02, -2.0160e-02, -1.0213e-01, -2.4322e-02,  2.8184e-02,\n",
       "           3.8127e-02,  2.4211e-02,  9.8264e-02, -4.5895e-02,  1.6286e-02,\n",
       "          -6.4621e-02,  7.8069e-02,  3.3484e-02, -1.7189e-02, -8.7503e-02,\n",
       "          -3.0487e-02,  5.9092e-02,  1.0775e-01,  6.7141e-03],\n",
       "         [-1.9297e-02, -3.7670e-02, -9.5619e-02, -1.0544e-01, -6.7892e-02,\n",
       "           9.4012e-02, -9.4078e-02,  2.9869e-02, -9.4906e-02,  6.3836e-02,\n",
       "          -8.3449e-02,  6.7446e-02,  6.9498e-02, -7.0019e-02,  9.9151e-02,\n",
       "          -4.4508e-02,  3.1645e-02, -3.6762e-03, -4.7189e-02,  1.0844e-01,\n",
       "          -4.2547e-02, -6.5274e-02, -1.3412e-02,  3.4493e-02, -7.4980e-02,\n",
       "           7.9584e-02, -2.0292e-02, -8.8643e-02,  6.0480e-02, -4.8612e-02,\n",
       "           5.0776e-02,  6.7979e-02,  6.8762e-02, -2.7990e-02,  1.4169e-02,\n",
       "           6.4253e-02, -7.3961e-02, -9.5909e-02, -5.3525e-02,  5.8299e-02,\n",
       "           5.3378e-02, -7.5132e-02,  4.4672e-02,  3.0977e-02, -4.8307e-02,\n",
       "           7.3997e-02,  7.3564e-02,  5.6902e-02,  4.6089e-02,  1.0875e-01,\n",
       "           1.9269e-02,  7.4493e-02, -6.7046e-02, -6.0282e-02, -3.2641e-02,\n",
       "          -6.0595e-02,  6.5429e-02, -1.0279e-01, -3.8933e-02, -8.3447e-02,\n",
       "          -1.3589e-02, -1.0016e-01, -4.2561e-03,  1.9290e-02, -4.4656e-03,\n",
       "           4.4789e-02, -2.3351e-03, -1.0116e-01,  9.7509e-02,  1.0508e-01,\n",
       "           8.8278e-02, -4.7772e-02,  6.5504e-02,  1.0376e-01, -6.4320e-02,\n",
       "           7.9238e-04, -9.2461e-02, -6.2427e-02,  3.5411e-02,  9.8474e-02,\n",
       "           2.0995e-02, -1.0097e-01, -2.1101e-03,  1.7914e-02]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.1017,  0.0868,  0.0182,  0.0034, -0.0854, -0.0975,  0.0146,  0.0856,\n",
       "         -0.0584, -0.0581], requires_grad=True)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
